{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbvTrwEJaMNP"
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9REYiEjduHg",
    "outputId": "aae26ad8-7d11-44b8-ac93-b8ff6cc3fef6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chatterbot\n",
      "  Downloading ChatterBot-1.0.8-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |█████▏                          | 10 kB 19.9 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 20 kB 12.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 30 kB 10.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 40 kB 9.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 51 kB 5.3 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 61 kB 5.8 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2018.9)\n",
      "Collecting sqlalchemy<1.4,>=1.3\n",
      "  Downloading SQLAlchemy-1.3.24-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 13.8 MB/s \n",
      "\u001b[?25hCollecting mathparse<0.2,>=0.1\n",
      "  Downloading mathparse-0.1.2-py3-none-any.whl (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from chatterbot) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
      "Installing collected packages: sqlalchemy, mathparse, chatterbot\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.31\n",
      "    Uninstalling SQLAlchemy-1.4.31:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.31\n",
      "Successfully installed chatterbot-1.0.8 mathparse-0.1.2 sqlalchemy-1.3.24\n"
     ]
    }
   ],
   "source": [
    "!pip install chatterbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Sjz-QSLrdvXv"
   },
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "U52yedSAdvTH"
   },
   "outputs": [],
   "source": [
    "cb = ChatBot(\"DataFolks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tagE9HCxdvSP"
   },
   "outputs": [],
   "source": [
    "tr = ListTrainer(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YA7X4x3FdvOJ",
    "outputId": "b6510846-5184-47c7-8e0d-4942a423aad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "tr.train([\"How can i help you\", \"I would love to find a course\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWrSaRjqdvNV",
    "outputId": "10f4dda8-98f6-4eca-c6dc-c543af8ba5e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can i help you\n"
     ]
    }
   ],
   "source": [
    "response = cb.get_response(\"hi\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "goYTgJ3CaMNP"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzrrwSOWaMNR",
    "outputId": "cab0381c-8bcf-4852-d162-07a6ff9052e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvlsVpMIaMNT"
   },
   "source": [
    "### Installing NLTK Packages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OCSnDZ8waMNU",
    "outputId": "49783f76-cb71-44c6-fc72-291a138fd450"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('popular', quiet=True) # for downloading packages\n",
    "nltk.download('punkt') # first-time use only\n",
    "nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "A2OXRDsFaMNV"
   },
   "outputs": [],
   "source": [
    "f=open('chatbot.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw = raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wx2OFsLyaMNX"
   },
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "tlE7WdSBaMNX"
   },
   "outputs": [],
   "source": [
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nW3KH2TFaMNY"
   },
   "outputs": [],
   "source": [
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]\n",
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hj76vpYfSXwI"
   },
   "outputs": [],
   "source": [
    "Greeting_inputs =(\"hello\", \"hi\", \"hey\")\n",
    "GREETING_RESPONSES = [\"I am glad\", \"hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "23b3_SL-S1h4"
   },
   "outputs": [],
   "source": [
    "def greeting(sentence):\n",
    "  for word in sentence.split():\n",
    "    if word.lower() in Greeting_inputs:\n",
    "      return random.choice(GREETING_RESPONSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "9XAvOJ9hTdVW"
   },
   "outputs": [],
   "source": [
    "def response2(user_response):\n",
    "  respond= \"\"\n",
    "  sent_tokens.append(user_response)\n",
    "  tfidfvec = TfidfVectorizer(tokenizer=LemNormalize, stop_words=\"english\")\n",
    "  tfidf = tfidfvec.fit_transform(sent_tokens)\n",
    "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "  idx = vals.argsort()[0][-2]\n",
    "  flat = vals.flatten()\n",
    "  flat.sort()\n",
    "  req_tfidf = flat[-2]\n",
    "  if(req_tfidf==0):\n",
    "    respond= respond+\"I am sorry, i dont understand\"\n",
    "    return respond\n",
    "  else:\n",
    "    respond= respond + sent_tokens[idx]\n",
    "    return respond\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k_QKc1cIWtfq",
    "outputId": "f78a3a91-dea8-435b-9db0-e9e16705f4fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siri : My name is siri\n",
      "hi\n",
      "Siri hi\n",
      "i need information wrt artificial intelligence course\n",
      "Siri: i need information wrt artificial intelligence course\n",
      "advertisement\n",
      "Siri: malicious use\n",
      "malicious chatbots are frequently used to fill chat rooms with spam and advertisements, by mimicking human behaviour and conversations or to entice people into revealing personal information, such as bank account numbers.\n",
      "products and services\n",
      "Siri: maintenance\n",
      "to keep chatbots up to speed with changing company products and services, traditional chatbot development platforms require ongoing maintenance.\n",
      "thank you\n",
      "Siri : u r welcm\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "\n",
    "print(\"Siri : My name is siri\")\n",
    "while(flag==True):\n",
    "  response1= input()\n",
    "  response1= response1.lower()\n",
    "  if(response1!=\"bye\"):\n",
    "    if(response1==\"thanks\" or response1==\"thank you\"):\n",
    "      flag=False\n",
    "      print(\"Siri : u r welcm\")\n",
    "    else:\n",
    "      if(greeting(response1)!=None):\n",
    "        print(\"Siri \"+ greeting(response1))\n",
    "      else:\n",
    "        print(\"Siri: \", end=\"\")\n",
    "        print(response2(response1))\n",
    "        sent_tokens.remove(response1)\n",
    "  else:\n",
    "    flag= False\n",
    "    print(\"bye tc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64gATZVdYgKt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Chatbot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
